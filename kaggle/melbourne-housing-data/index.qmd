---
title: Fun With Melbourne Housing Data
description: |
  Making some models and figures using Melbourne housing data from the 
  dataset [anthonypino/melbourne-housing-market](kaggle.com/datasets/anthonypino/melbourne-housing-market). 
  Notes from the first two assignments from ``dansbecker``s course and
  exposition.
image: thumb.png
extra:
  url: /kaggle/melbourne-housing-data
  image: /kaggle/melbourne-housing-data/thumb.png
keywords:
  - austrailia
  - seaborn
  - numpy 
  - sklearn
  - scikit-learn
  - datascience
  - data
  - science
catagories:
  - python
  - kaggle
---

These notes/assignments were done along with the following parts of 
``dansbecker``s course:

- [Basic Data Exploration](https://kaggle.com/code/dansbecker/basic-data-exploration)
- [Your First ML Model](https://kaggle.com/code/dansbecker/your-first-machine-learning-model)


## About Using ``kaggle`` Outside of the Browser

Since this is the first assignment, and since I would much rather automate 
things, I would like to say that it is worth knowing that the kaggle API has a
``python`` client available on ``PyPI``. This may be installed using ``pip 
install kaggle`` or in my case ``poetry add kaggle``. 

It turns out that the ``kaggle`` library is not the only client available for 
using ``kaggle`` in ``python`` modules. There is also a solution called 
``kagglehub``. It can be installed like ``poetry add kagglehub``.

The dataset for this assignment can be [viewed and downloaded in the browser](
https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot?resource=download).
It may be obtained in ``python`` as follows:


```{python}
import kagglehub
import pathlib
import io
import contextlib

import numpy as np
import pandas as pd


DIR = pathlib.Path(".").resolve()

# NOTE: The ``path`` argument does not specify the path downloaded to, but 
#       instead a subpath of the data.
DATA_DOWNLOAD_IO = io.StringIO()
DATA_ID ="anthonypino/melbourne-housing-market" 
with contextlib.redirect_stdout(DATA_DOWNLOAD_IO):
  DATA_DIR = pathlib.Path(kagglehub.dataset_download(DATA_ID))

DATA_PATH_LESS = DATA_DIR / "MELBOURNE_HOUSE_PRICES_LESS.csv"
DATA_PATH = DATA_DIR / "Melbourne_housing_FULL.csv"
```


## Describing Data

Note that it is necessary to capture ``stdout`` if you want your notebook to
look nice. The output in ``DATA_PATH`` should be a path to the data full data,
and (obviously) ``DATA_PATH_LESS`` should be a path to the partial data. It
will look something like


```{python}
#| echo: false
#| code-overflow: wrap
print(DATA_PATH)
```


Data is loaded an described using the following:


```{python}
#| fig-cap: Description of the dataset in ``MELBOURNE_HOUSE_PRICES_LESS.csv``.
DATA_LESS = pd.read_csv(DATA_PATH_LESS)
DATA_LESS.describe()
```


This is roughly what was done on the first assignment but with a different
data set (this one came from the example before) the homework assignment. 
Further the assignment asked for some interpretation of the data set 
description.


## More About Pandas

I will go ahead and write about pandas a little more as notes on the next 
tutorial and for my own review. 

The columns of the ``DataFrame`` are able to be viewed using the ``columns`` 
attribute:


```{python}
#| fig-cap: Available columns.
DATA = pd.read_csv(DATA_PATH)
print(
  "Columns:", 
  *list(map(lambda item: f"- `{item}`", DATA)),
  sep="\n"
)
```


``pd.core.series.Series`` is very similar to ``pd.DataFrame`` and shares many 
attributes. For instance, we can describe an individual column:


```{python}
#| fig-cap: Description of the ``Distance`` column.

(DISTANCE := DATA["Distance"]).describe()
```


The following block of code confirms the type of ``DISTANCE`` and shows the 
useful attributes of ``pd.core.series.Series`` by filtering out methods and 
attributes that start with an underscore since they are often builtin or 
private:


```{python}
#| fig-cap: "Confirming that columns have type ``pd.core.series.Series``."
print("Type:", type(DISTANCE))
print(
  "Common Attributes:", 
  *list(
    map(
      lambda attr: f"- {attr}", 
      filter(
        lambda attr: not attr.startswith("_"), 
        set(dir(DISTANCE)) & set(dir(DATA))
      )
    )
  ), 
  sep="\n",
)
```


Null columns can be removed from the ``DataFrame`` using the ``dropna`` method.
This does not modify in place the ``DataFrame``, rather it returns a new 
``DataFrame`` (unless the ``inplace`` keyword argument is used):


```{python}
#| fig-cap: Description of the data minus null rows.
DATA = DATA.dropna(axis='index')
DATA.describe()
```


The ``axis`` keyword argument of ``DataFrame.dropna`` is used to determine 
if rows (aka ``index`` or 0) or columns (``columns`` or 1) with null values are 
dropped. From this data a certain number of columns can be selected using a 
list as an index:


```{python}
#| fig-cap: First ten rows of ``DATA``.
DATA_FEATURES_COLUMNS = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
DATA_FEATURES = DATA[DATA_FEATURES_COLUMNS]
DATA_FEATURES.head(10)

DATA_PREDICTION_TARGET = DATA["Price"]
```


# About ``scikit-learn`` Learn

It is easy to install ``scikit-learn`` using poetry or pip like


```sh
poetry add scikit-learn
```


It is also easy to use ``sklearn`` to attempt to predict the prices of the 
first ten houses:


```{python}
from sklearn.tree import DecisionTreeRegressor

TREE = DecisionTreeRegressor(random_state=1)
TREE.fit(DATA_FEATURES, DATA_PREDICTION_TARGET)

PRICE_PREDICTIONS = TREE.predict(
  DATA_FEATURES.head(10000)
)
```


compare the outputs:


```{python}
#| fig-cap: Predicted vs Actual Prices
PRICE_COMPARE = pd.DataFrame(
  {
    "predicted": PRICE_PREDICTIONS,
    "actual": (PRICE_ACTUAL := list(DATA["Price"].head(10000))), 
    "error": list(
      round(abs((actual - predicted)/actual), 8) 
      for predicted, actual in zip(PRICE_PREDICTIONS, PRICE_ACTUAL)
    )
  }
)

PRICE_COMPARE.head(10)
```


and calculate the total magnitude of error column using the $L^2$ norm:


```{python}
print(PRICE_ERROR_NORM := np.sqrt(sum(PRICE_COMPARE.error**2)))
```


which implies that a (very liberal) upper bound for the error is 


```{python}
print(f"{PRICE_ERROR_NORM / DATA['Price'].max():.8%}")
```



